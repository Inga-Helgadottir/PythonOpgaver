{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 01 Class exercise slicing dataframe\n",
    "Use this data:\n",
    "```python\n",
    "data = np.array([['','Col1','Col2','col3'],\n",
    "                ['Row1',1,2,3],\n",
    "                ['Row2',4,5,6],\n",
    "                ['Row3',7,8,9]])\n",
    "```\n",
    "1. Create a DataFrame (wrap the data above in a pandas DataFrame in a way that printing the dataframe and its index and column attributes gives this result)  \n",
    "`pd.DataFrame(data=data[1:4,1:4], columns=data[0,1:4], index=data[1:4,0])`  \n",
    "\n",
    "``` \n",
    "     Col1 Col2 col3  \n",
    "Row1    1    2    3\n",
    "Row2    4    5    6\n",
    "Row3    7    8    9\n",
    "\n",
    "Index(['Row1', 'Row2', 'Row3'], dtype='object')\n",
    "Index(['Col1', 'Col2', 'col3'], dtype='object')\n",
    "```\n",
    "\n",
    "2. Make slices of data:\n",
    "   1. second column using column name\n",
    "   2. third column using column index (.iloc[])\n",
    "   3. slice element at third row of second column (use .iloc())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "#1. Create a DataFrame (wrap the data above in a pandas DataFrame in a way that printing the dataframe and its index and column attributes gives this result)\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "data = np.array([['','Col1','Col2','col3'],\n",
    "                ['Row1',1,2,3],\n",
    "                ['Row2',4,5,6],\n",
    "                ['Row3',7,8,9]])\n",
    "\n",
    "dataDF = pd.DataFrame(data=data[1:4,1:4], columns=data[0,1:4], index=data[1:4,0])\n",
    "# print(data1)\n",
    "\n",
    "#2. Make slices of data:\n",
    "    #2a. second column using column name\n",
    "    \n",
    "data2a = dataDF['Col2']\n",
    "# print(data2a)\n",
    "\n",
    "    #2b. third column using column index (.iloc[])\n",
    "    \n",
    "data2b = dataDF.iloc[:, 2]\n",
    "# print(data2b)\n",
    "\n",
    "    #2c. slice element at third row of second column (use .iloc())\n",
    "    \n",
    "data2c = dataDF.iloc[2, 1]\n",
    "print(data2c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 02 Exercise Pandas Data Series\n",
    "The CO2 Emission data set above is not updated since 2014\n",
    "1. Create a Pandas Series with emission data from 2014 for each country or region\n",
    "2. Find the 10 Countries/Regions with the highest emissions in 2014 and show emission numbers (reverse sorted)\n",
    "3. Remove if you can those rows that are not countries (regions and aggregated groups) (hint:  [ISO 3166, Alpha-3 country codes](https://www.iban.com/country-codes), a csv file can be found here: `/data/country_codes.csv`)\n",
    "    - Find the 10 countries with highest emissions in 2014\n",
    "4. Plot the emissions of China and USA over time respectively"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 03 Exercise pandas dataframe\n",
    "1. Using the dataframe in the above cell find:\n",
    "    1. Mean, Min, Max values for all 4 columns\n",
    "    2. The 2 dates with the largest and smallest sum (by column)\n",
    "    3. All dates where both A's and B's are positive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 04 Class Exercise\n",
    "#### Find military expenditure pr. capita.\n",
    "\n",
    "Go here and get data as csv: [worldbank military expanditure](https://databank.worldbank.org/reports.aspx?source=2&series=MS.MIL.XPND.CD&country=#). Download it manually, unzip the csv and clean up empty rows.  \n",
    "1. Use .replace() method on the dataframe to remove all data containing '..'\n",
    "2. Set index of the dataframe to be 'Country Name'\n",
    "3. Slice the 2019 column data to get a data series.\n",
    "4. Make data numeric (pd.to_numeric(data_series))\n",
    "\n",
    "1. For 2019 find the 10 countries with the highest military expenditure in USD\n",
    "2. For 2019 find the 10 countries with the highest military expenditure per capita. Find the population data here: [worldbank](https://databank.worldbank.org/source/world-development-indicators/preview/on#)(use series='Population,Total' and time='2019' and Country= countries (217)) **or** use [copy paste with this date into excel](https://www.worldometers.info/world-population/population-by-country/)\n",
    "  - (Hint: use pd.merge() to merge the mil_exp dataframe with the population dataframe on 2 columns (country_code)\n",
    "3. For 2019 find the 3 countries with the highest per capita military expenditure in the middle east\n",
    "  - [countries list with iso code](middleeast_countries.csv) or use:   \n",
    "  `list_of_middle_eastern = ['YEM','ARE','TUR','SYR','SAU','QAT','PSE','OMN','LBN','KWT','JOR','ISR','IRQ','IRN','EGY','CYP','BHR']`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n",
    "## Self study exercise\n",
    "\n",
    "Complete the comparison of military expenditures by converting all currencies to USD. Since we have yearly expenditures, use for example the yearly median for normalization. Likely, you will find an API to collect historical echange rates at Yahoo Finance.\n",
    "\n",
    "[https://finance.yahoo.com/quote/USDRUB%3DX](https://finance.yahoo.com/quote/USDRUB%3DX)\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
